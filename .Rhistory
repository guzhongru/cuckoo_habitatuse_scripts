#### LOAD WORKSPACE ####
#load("~/Git/cuckoos/PA corine extraction.RData")
#load("~/cuckoos/PA corine temp precip extraction.RData") # load workspace on cluster
load("~/Git/cuckoos/PA epsg3035 corine temp precip extraction.RData") # load workspace on PC
#### TO RUN ON CLUSTER, CHANGE BELOW LINE ####
cluster <- FALSE
#### TO RUN RANDOM MCPs, CHANGE BELOW LINE ####
generaterandom <- FALSE
#randomradius <- c(50000, 100000, 200000, 500000) # change to desired search radius for randomized pseudoabsence polygon, in metres
randomradius <- c(50000) # change to desired search radius for randomized pseudoabsence polygon, in metres
#### TO CHANGE NUMBER OF PSEUDO-ABSENCES GENERATED, CHANGE BELOW LINE ####
n.absences <- 10
#### TO CHANGE NUMBER OF INDIVIDUALS, CHANGE BELOW LINE ####
n.birds <- 31
library(sp) # converts R dataframes into spatially explicit dta
library(maptools) # allows import of shapefiles into R
library(rgdal)
library(rgeos)
library(raster)
library(geosphere)
library(shape)
library(adehabitatHR)
library(SPEI)
install.packages("maptools")
library(maptools) # allows import of shapefiles into R
?uninstall
remove.packages(maptools)
installed.packages()
200 *1000
(1000*1000)/(200*1000)
.2*1
1/0.2
?rename
load("~/Git/curlew_change/workspaces/temporary rescue point 2 C..Rdata")
library(mrds)
library(reshape)
# library(unmarked)
ls
ls()
if (length(grep("habs1", final.par) > 0)) {
habs1 <- as.vector(names(table(bird.dat9$habs1)))
# if using both visits, early=1 and late=0
if (Visit=="B") {
newdat <- data.frame(habs1=rep(habs1, times=2), visit=rep(c(0,1), each=length(habs1)), distbegin=rep(0, each=length(habs1)*2), distend=rep(25, each=length(habs1)*2)) # for both early and late visits
}
# if using early visit only, early=1
if (Visit=="E") {
newdat <- data.frame(habs1=habs1, visit=rep(mean(bird.s5$visit),length(habs1)), distbegin=rep(0, each=length(habs1)), distend=rep(25, each=length(habs1)))
}
# if using late visit only, early=0
if (Visit=="L") {
newdat <- data.frame(habs1=habs1, visit=rep(mean(bird.s5$visit),length(habs1)), distbegin=rep(0, each=length(habs1)), distend=rep(25, each=length(habs1)))
}
fitted <- predict(final, newdata=newdat, compute=T)$fitted
fit <- data.frame(newdat, fitted)
fit <- rename(fit, c("habs1"="habs"))
# Match up pooled habitats:
ha <- as.data.frame(cbind(1:9,habs))
ha2 <- merge(ha,fit,by="habs",all.x=T)
fit.hab <- as.numeric(as.character(ha2$fitted))
calc.square.det <- function(bird.dataset) { # this function works much faster than loop method used in code from Ali/Dario
# Calculate the counts in each habitat and the weights (e.g. 2 birds in habCdt and 3 in habDdt):
ct <- as.numeric(bird.dataset[habdt.col]) # counts in each habitat
tr <- as.numeric(bird.dataset[habtr.col]) # transects in each habitat
wt <- ct+tr # adds the counts in each habitat to the number of transects in that habitat (e.g. 5+2=7 in habC and 5+3=8 in habD; habitat weights will be higher if there are a) more transects of that habitat in the square; or b) more counts in that habitat in the square)
fit.dat <- data.frame(ct.no=ct, tr.no=tr, wt=ct+tr, fit.hab=fit.hab)
# Calculate the square detectability:
# "Average weighted" detectability for a square is based on the detectability of each of the habitat types in the square (according to the predictions of the fitted transect detectability model that contains habitat as a covariate), and, the relative amount of a habitat in the square (determined by number of transects) and proportion of counts that the habitat contributes to the total number of counts
# average weighted detectability = sum of all fitted value for the habitat types in the square * weight value of that habitat type, divided by the sum total habitat weights
multiply <- function(x) Reduce("*", x)
fit.vec.dt <- sum(multiply(fit.dat[,c("wt","fit.hab")]))/sum(fit.dat$wt)
return(fit.vec.dt)
}
fit.vec <- apply(bird.s5, 1, calc.square.det)
}
final.par <- names(final$par)[which(names(final$par) != "X.Intercept.")]
####---- Square level detectability for ddf with habitat + visit covariate ----####
# Calculate average weighted square detectability based on square habitats present, amount of those habitats, and number of counts in those habitats
# use transect detectability model to predict detectability for a new dataset with every combination of covariates in the detectability model (e.g. if habitat and visit in the model, then predict detectability for all present habitat types and for required visit type - E, L or both)
if (length(grep("habs1", final.par) > 0)) {
habs1 <- as.vector(names(table(bird.dat9$habs1)))
# if using both visits, early=1 and late=0
if (Visit=="B") {
newdat <- data.frame(habs1=rep(habs1, times=2), visit=rep(c(0,1), each=length(habs1)), distbegin=rep(0, each=length(habs1)*2), distend=rep(25, each=length(habs1)*2)) # for both early and late visits
}
# if using early visit only, early=1
if (Visit=="E") {
newdat <- data.frame(habs1=habs1, visit=rep(mean(bird.s5$visit),length(habs1)), distbegin=rep(0, each=length(habs1)), distend=rep(25, each=length(habs1)))
}
# if using late visit only, early=0
if (Visit=="L") {
newdat <- data.frame(habs1=habs1, visit=rep(mean(bird.s5$visit),length(habs1)), distbegin=rep(0, each=length(habs1)), distend=rep(25, each=length(habs1)))
}
fitted <- predict(final, newdata=newdat, compute=T)$fitted
fit <- data.frame(newdat, fitted)
fit <- rename(fit, c("habs1"="habs"))
# Match up pooled habitats:
ha <- as.data.frame(cbind(1:9,habs))
ha2 <- merge(ha,fit,by="habs",all.x=T)
fit.hab <- as.numeric(as.character(ha2$fitted))
calc.square.det <- function(bird.dataset) { # this function works much faster than loop method used in code from Ali/Dario
# Calculate the counts in each habitat and the weights (e.g. 2 birds in habCdt and 3 in habDdt):
ct <- as.numeric(bird.dataset[habdt.col]) # counts in each habitat
tr <- as.numeric(bird.dataset[habtr.col]) # transects in each habitat
wt <- ct+tr # adds the counts in each habitat to the number of transects in that habitat (e.g. 5+2=7 in habC and 5+3=8 in habD; habitat weights will be higher if there are a) more transects of that habitat in the square; or b) more counts in that habitat in the square)
fit.dat <- data.frame(ct.no=ct, tr.no=tr, wt=ct+tr, fit.hab=fit.hab)
# Calculate the square detectability:
# "Average weighted" detectability for a square is based on the detectability of each of the habitat types in the square (according to the predictions of the fitted transect detectability model that contains habitat as a covariate), and, the relative amount of a habitat in the square (determined by number of transects) and proportion of counts that the habitat contributes to the total number of counts
# average weighted detectability = sum of all fitted value for the habitat types in the square * weight value of that habitat type, divided by the sum total habitat weights
multiply <- function(x) Reduce("*", x)
fit.vec.dt <- sum(multiply(fit.dat[,c("wt","fit.hab")]))/sum(fit.dat$wt)
return(fit.vec.dt)
}
fit.vec <- apply(bird.s5, 1, calc.square.det)
}
if (length(grep("vis", final.par) > 0)) {
# newdat <- data.frame(visit=rep(c(0,1), each=3), vis=rep(c(1,2,3), times=2), distbegin=rep(c(0,25), each=6), distend=rep(c(25,100), each=6)) # calculate detectability at each level of visibility and visit
# fitted <- predict(final, newdat, compute=T)$fitted
newdat <- bird.s5[,c(final.par, "distbegin", "distend")]
fit.vec <- predict(final, newdata=newdat, compute=T)$fitted
}
(grep("vis", final.par)
)
final.par
?grep
(grep("vis", final.par, fixed=TRUE))
match("vis", final.par)
match("visit", final.par)
if (length(grep("vis", final.par) > 0)) {
# newdat <- data.frame(visit=rep(c(0,1), each=3), vis=rep(c(1,2,3), times=2), distbegin=rep(c(0,25), each=6), distend=rep(c(25,100), each=6)) # calculate detectability at each level of visibility and visit
# fitted <- predict(final, newdat, compute=T)$fitted
newdat <- bird.s5[,c(final.par, "distbegin", "distend")]
fit.vec <- predict(final, newdata=newdat, compute=T)$fitted
}
length(match("vis", final.par))
!(is.na(match("vis", final.par)))
!(is.na(match("visit", final.par)))
length(grep("habs1", final.par)
)
if (!(is.na(match("vis", final.par)))) {
# newdat <- data.frame(visit=rep(c(0,1), each=3), vis=rep(c(1,2,3), times=2), distbegin=rep(c(0,25), each=6), distend=rep(c(25,100), each=6)) # calculate detectability at each level of visibility and visit
# fitted <- predict(final, newdat, compute=T)$fitted
newdat <- bird.s5[,c(final.par, "distbegin", "distend")]
fit.vec <- predict(final, newdata=newdat, compute=T)$fitted
}
Mac <- FALSE
if(.Platform$OS =='windows') cluster <- FALSE
if(.Platform$OS=='unix' & !Mac) cluster <- TRUE
# if (cluster) {
#   Args <- commandArgs()[3]
#
#   route <- substr(Args,1,2)  # SW/SE
#   randomradius <- as.numeric(substr(Args,3,5)) # 50, 100, 200, or 500km
#   analysistype <- substr(Args,6,7)
# }
#
# if (!cluster) {
#   route <- "DE"
#   randomradius <- 200
#   analysistype <- "DE"
# }
if (cluster) {
library(plyr)
library(reshape)
#library(glmmML)
library(lme4)
library(arm)
}
if (!cluster) {
library(plyr)
library(reshape)
#library(glmmML)
library(lme4)
library(arm)
library(ggplot2)
library(scales)
library(sp)
library(rgeos)
library(rgdal)
library(MuMIn)
}
###----------------------------------------------###
####         SET WORKING DIRECTORIES		####
###----------------------------------------------###
if (!cluster) {
if (!Mac) parentwd <- c("C:/Users/samf/Documents/Git/cuckoos")
if (Mac) parentwd <- c("/Volumes/SAM250GB/BTO PC Documents/Git/cuckoos")
}
# BTO HPC cluster
# if (cluster) parentwd <- c("/users1/samf/cuckoos")
# Wales HPC cluster
if (cluster) parentwd <- c("/home/samantha.franks/cuckoos")
datawd <- paste(parentwd, "/data", sep="")
outputwd <- paste(parentwd, "/output/autumn LOS and Sahara success analysis", sep="")
workspacewd <- paste(parentwd, "/workspaces", sep="")
####==== IMPORT POINT DATA - only need presences for Sahara success ====####
setwd(paste(datawd, "/data for analysis/", sep=""))
present <- read.csv("presence data all variables points all with country data.csv", header=T)
# revalue Sahara success for John (incorrect in main data sheet) => "Y" should be "N"
present[present$name=="John", "Sahara.success"] <- "N"
### ----------------------------- ###
####        DATA PREPARATION     ####
### ------------------------------###
#### ---- CORRECT COLUMN NAMES OF DATASET SO CAN MERGE ---- ####
newpresent <- rename(present, c("newlongs.epsg3035"="long.epsg3035", "newlats.epsg3035"="lat.epsg3035", "newlongs.epsg4326"="long.epsg4326", "newlats.epsg4326"="lat.epsg4326"))
#### ---- ADD STOPOVER DURATION TO DATA ---- ####
### creates 2 files: present.LOS and absent.LOS with length of stay data added onto present and absent datasets
setwd(paste(parentwd, "/scripts/", sep=""))
source("source code to add stopover duration data for analysis.R")
present.LOS <- present.LOS[,-which(names(present.LOS) %in% c("datetime"))]
present.LOS <- present.LOS[c(2,1,3:length(present.LOS))]
present.LOS$mgroup <- as.factor(present.LOS$mgroup)
present.LOS <- rename(present.LOS, c("LAND.CLASS"="habitat", "PAoverlap"="PA", "elevation.m"="elevation", "Sahara.success"="success"))
#### ---- CONVERT POINT DATA TO STOPOVER DATA FOR **FINAL STOPOVERS ONLY** ---- ####
### remove birds that had unsuccessful crossing due to tag failure: Wallace
# only want to include birds that are presumed dead in Europe or on crossing or which likely died in Europe or on crossing (gleaned from text of BTO cuckoos page)
finalstops <- subset(present.LOS, laststop=="Y" & name!="Wallace")
finalstops <- droplevels(finalstops)
### habitat
bybird <- split(finalstops, list(finalstops$name))
bybird2 <- lapply(bybird, function(x) {x$mgroup <- droplevels(x$mgroup); x$name <- droplevels(x$name); return(x)})
habitatsum <- lapply(bybird2, function(x) prop.table(table(x$mgroup, x$habitat), 1))
### PA: proportion of points in mgroup overlapping with PA, if no overlap (100% of points are a N), then classify that mgroup as a N for PAoverlap
PAsum <- lapply(bybird2, function(x) prop.table(table(x$mgroup, x$PA), 1))
PA.YN <- lapply(PAsum, function(x) revalue(as.factor(x[,1] == 1), c("TRUE"="N", "FALSE"="Y"))) # identifies as TRUE mgroups which have 100% of points in the "No PA overlap" column
### elevation
meanelevation <- lapply(bybird2, function(x) tapply(x$elevation, x$mgroup, mean))
### climate
mean.spei.Mar <- lapply(bybird2, function(x) tapply(x$spei.Mar, x$mgroup, mean))
mean.spei.Aug <- lapply(bybird2, function(x) tapply(x$spei.Aug, x$mgroup, mean))
### success
success <- lapply(bybird2, function(x) prop.table(table(x$year, x$success), 1))
### LOS
LOS <- lapply(bybird2, function(x) tapply(x$LOS, x$mgroup, mean))
# names <- do.call(rbind, lapply(bybird2, function(x) unique(x[c("name","mgroup","year")])))
names <- do.call(rbind, lapply(bybird2, function(x) data.frame(name=levels(x$name), mgroup=levels(x$mgroup))))
#### ---- MODEL DATASET ---- ####
dat <- data.frame(names, do.call(rbind, habitatsum), PA=unlist(PA.YN), elevation=rescale(unlist(meanelevation)), spei.Mar=unlist(mean.spei.Mar), spei.Aug=unlist(mean.spei.Aug), year=unlist(lapply(success, rownames)), success=unlist(lapply(success, function(x) x[,2])), LOS=unlist(LOS))
########################################################################
m <- list()
m[[1]] <- glmer(success ~ 1 + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[2]] <- glmer(success ~ PA + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[3]] <- glmer(success ~ elevation + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[4]] <- glmer(success ~ spei.Mar + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[5]] <- glmer(success ~ spei.Aug + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[6]] <- glmer(success ~ agriculture + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[7]] <- glmer(success ~ forest + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[8]] <- glmer(success ~ scrub.grassland + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[9]] <- glmer(success ~ unsuitable + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[10]] <- glmer(success ~ wetland.water + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[11]] <- glmer(success ~ forest + scrub.grassland + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
# drop model, max|grad| is too high (11.57)
# m[[12]] <- glmer(success ~ forest + scrub.grassland + wetland.water + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[12]] <- glmer(success ~ PA + agriculture + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[13]] <- glmer(success ~ PA + forest + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[14]] <- glmer(success ~ PA + scrub.grassland + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[15]] <- glmer(success ~ PA + unsuitable + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[16]] <- glmer(success ~ PA + wetland.water + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[17]] <- glmer(success ~ PA + forest + scrub.grassland + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[18]] <- glmer(success ~ PA + forest + scrub.grassland + wetland.water + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[19]] <- glmer(success ~ agriculture*PA + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[20]] <- glmer(success ~ forest*PA + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[21]] <- glmer(success ~ scrub.grassland*PA + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
m[[22]] <- glmer(success ~ PA + agriculture + forest + scrub.grassland + wetland.water + elevation + spei.Mar + spei.Aug + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
# drop model max|grad| is too high (84.9, tol=0.001)
# m[[14]] <- glmer(success ~ unsuitable*PA + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
# drop model, rank deficient
# m[[15]] <- glmer(success ~ wetland.water*PA + (1|name), data=dat, family=binomial, control=glmerControl(optimizer="bobyqa"))
###======== OUTPUT RESULTS ========###
output.mumin <- model.sel(m)
modavg.mumin <- model.avg(output.mumin)
output.mumin
modavg.mumin
names(modavg.mumin)
summary(modavg.mumin)
citatin(MuMIn)
citation(MuMIn)
